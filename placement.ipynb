{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Either we can run NN or we can run other algorithms\n",
    "#import the package\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Reading csv file\n",
    "df1=pd.read_csv(r\"Master-Data_2019.csv\",header=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 46)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Degree 1 Specializations', 'Campus', 'Gender',\n",
       "       'Current Aggregate Marks', 'Semester 1 Aggregate Marks',\n",
       "       'Back Papers.1', 'Pending Back Papers.1', 'Semester 2 Aggregate Marks',\n",
       "       'Back Papers.2', 'Pending Back Papers.2', 'Semester 3 Aggregate Marks',\n",
       "       'Back Papers.3', 'Pending Back Papers.3', 'Semester 4 Aggregate Marks',\n",
       "       'Back Papers.4', 'Pending Back Papers.4', 'Semester 5 Aggregate Marks',\n",
       "       'Back Papers.5', 'Pending Back Papers.5', 'Semester 6 Aggregate Marks',\n",
       "       'Back Papers.6', 'Pending Back Papers.6', 'Semester 7 Aggregate Marks',\n",
       "       'Back Papers.7', 'Pending Back Papers.7', '12thAggregate Marks',\n",
       "       '10th Aggregate Marks', 'Diploma Aggregate Marks', 'dead_back_log',\n",
       "       'live_atkt', 'Job Offer Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the columns \n",
    "df1.drop(['No.', 'Degree', 'Roll No','First Name', 'Middle Name', 'Last Name','Date of Birth', 'Back Papers','Pending Back Papers','Eligible But Not Registered Count', 'Registered But Not Offer Count','Semester 8 Aggregate Marks','Back Papers.8', 'Pending Back Papers.8','year_down'], axis=1, inplace=True)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 Specializations        16\n",
      "Campus                           0\n",
      "Gender                          16\n",
      "Current Aggregate Marks        239\n",
      "Semester 1 Aggregate Marks     777\n",
      "Back Papers.1                 1749\n",
      "Pending Back Papers.1         1833\n",
      "Semester 2 Aggregate Marks     745\n",
      "Back Papers.2                 1700\n",
      "Pending Back Papers.2         1826\n",
      "Semester 3 Aggregate Marks     306\n",
      "Back Papers.3                 1518\n",
      "Pending Back Papers.3         1708\n",
      "Semester 4 Aggregate Marks     335\n",
      "Back Papers.4                 1646\n",
      "Pending Back Papers.4         1758\n",
      "Semester 5 Aggregate Marks     457\n",
      "Back Papers.5                 1633\n",
      "Pending Back Papers.5         1758\n",
      "Semester 6 Aggregate Marks     550\n",
      "Back Papers.6                 1728\n",
      "Pending Back Papers.6         1753\n",
      "Semester 7 Aggregate Marks    1804\n",
      "Back Papers.7                 2158\n",
      "Pending Back Papers.7         2158\n",
      "12thAggregate Marks            626\n",
      "10th Aggregate Marks            61\n",
      "Diploma Aggregate Marks       1721\n",
      "dead_back_log                 1978\n",
      "live_atkt                     2112\n",
      "Job Offer Count                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df= df1.copy(deep=True) # make a copy and keep original dataframe\n",
    "temp_y=df['Job Offer Count']\n",
    "df= df.drop('Job Offer Count', axis=1)\n",
    "df = pd.concat([df,temp_y],axis=1)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering before model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    #df.drop(df.loc[df['Degree']=='M.Tech.'].index, inplace=True) #Dropping the M.Tech values from the Degree Columns\n",
    "    df.drop(df.loc[df['Campus']=='MIT - WPU'].index, inplace=True) #Dropping the MIT-PWU values from the campus Columns\n",
    "    \n",
    "    #Rename Columns\n",
    "    df.rename(columns={'Degree 1 Specializations':'BRANCH'},inplace=True)\n",
    "    df.rename(columns={'Current Aggregate Marks':'BE_Aggregate_Marks'},inplace=True)\n",
    "    df.rename(columns={'Semester 1 Aggregate Marks':'Semester1_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.1':'BackPapers1'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.1':'P_BackPapers1'},inplace=True)\n",
    "    df.rename(columns={'Semester 2 Aggregate Marks':'Semester2_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.2':'BackPapers2'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.2':'P_BackPapers2'},inplace=True)\n",
    "    df.rename(columns={'Semester 3 Aggregate Marks':'Semester3_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.3':'BackPapers3'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.3':'P_BackPapers3'},inplace=True)\n",
    "    df.rename(columns={'Semester 4 Aggregate Marks':'Semester4_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.4':'BackPapers4'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.4':'P_BackPapers4'},inplace=True)\n",
    "    df.rename(columns={'Semester 5 Aggregate Marks':'Semester5_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.5':'BackPapers5'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.5':'P_BackPapers5'},inplace=True)\n",
    "    df.rename(columns={'Semester 6 Aggregate Marks':'Semester6_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.6':'BackPapers6'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.6':'P_BackPapers6'},inplace=True)\n",
    "    df.rename(columns={'Semester 7 Aggregate Marks':'Semester7_Marks'},inplace=True)\n",
    "    df.rename(columns={'Back Papers.7':'BackPapers7'},inplace=True)\n",
    "    df.rename(columns={'Pending Back Papers.7':'P_BackPapers7'},inplace=True)\n",
    "   # df.rename(columns={'Semester 8 Aggregate Marks':'Semester8_Marks'},inplace=True)\n",
    "   # df.rename(columns={'Back Papers.8':'BackPapers8'},inplace=True)\n",
    "   # df.rename(columns={'Pending Back Papers.8':'P_BackPapers8'},inplace=True)\n",
    "    df.rename(columns={'12thAggregate Marks':'HSC_Marks'},inplace=True)\n",
    "    df.rename(columns={'10th Aggregate Marks':'SSC_Marks'},inplace=True)\n",
    "    df.rename(columns={'Diploma Aggregate Marks':'Diploma_Marks'},inplace=True)\n",
    "    df.rename(columns={'Job_Offer_Count':'Job_Offer'},inplace=True)\n",
    "    \n",
    "    #df['Current_Aggregate_Marks']=df[ 'Current_Aggregate_Marks'].fillna(value=0) #replacing NaN Values to 0 in current_agg_marks\n",
    "    \n",
    "    #Filling the null value\n",
    "    df['Gender'] = np.where(pd.isnull(df['Gender']), 'Male', df['Gender'])\n",
    "    \n",
    "    df[\"BRANCH\"]=np.where(pd.isnull(df['BRANCH']), 'Mechanical', df['BRANCH'])\n",
    "    df['BE_Aggregate_Marks']=df['BE_Aggregate_Marks'].fillna(df['BE_Aggregate_Marks'].mean())\n",
    "    df['Semester1_Marks']=df['Semester1_Marks'].fillna(df['Semester1_Marks'].mean())\n",
    "    df['Semester2_Marks']=df['Semester2_Marks'].fillna(df['Semester2_Marks'].mean())\n",
    "    df['Semester3_Marks']=df['Semester2_Marks'].fillna(df['Semester2_Marks'].mean())\n",
    "    df['Semester4_Marks']=df['Semester4_Marks'].fillna(df['Semester4_Marks'].mean())\n",
    "    df['Semester5_Marks']=df['Semester5_Marks'].fillna(df['Semester5_Marks'].mean())\n",
    "    df['Semester6_Marks']=df['Semester6_Marks'].fillna(df['Semester6_Marks'].mean())\n",
    "    df['Semester7_Marks']=df['Semester7_Marks'].fillna(df['Semester7_Marks'].mean())\n",
    "   # df['Semester8_Marks']=df['Semester8_Marks'].fillna(df['Semester8_Marks'].mean())\n",
    "    \n",
    "    df['HSC_Marks']=df['HSC_Marks'].fillna(df['HSC_Marks'].mean())\n",
    "    df['SSC_Marks']=df['SSC_Marks'].fillna(df['SSC_Marks'].mean())\n",
    "    df['Diploma_Marks']=df['Diploma_Marks'].fillna(df['Diploma_Marks'].mean())    \n",
    "    \n",
    "    \n",
    "    df['BackPapers1']=df['BackPapers1'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['P_BackPapers1']=df['P_BackPapers1'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers2']=df['BackPapers2'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['P_BackPapers2']=df['P_BackPapers2'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers3']=df['BackPapers3'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['P_BackPapers3']=df['P_BackPapers3'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers4']=df['BackPapers4'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['P_BackPapers4']=df['P_BackPapers4'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers5']=df['BackPapers5'].fillna(value=0) #replacing NaN Values to 0\n",
    "    df['P_BackPapers5']=df['P_BackPapers5'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers6']=df['BackPapers6'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['P_BackPapers6']=df['P_BackPapers6'].fillna(value=0) #replacing NaN Values to 0 \n",
    "    df['BackPapers7']=df['BackPapers7'].fillna(value=0) #replacing NaN Values to 0  \n",
    "    df['P_BackPapers7']=df['P_BackPapers7'].fillna(value=0) #replacing NaN Values to 0 \n",
    "   # df['BackPapers8']=df['BackPapers8'].fillna(value=0) #replacing NaN Values to 0  \n",
    "   # df['P_BackPapers8']=df['P_BackPapers8'].fillna(value=0) #replacing NaN Values to 0 \n",
    "\n",
    "    df['live_atkt']=df['live_atkt'].fillna(value=0) #replacing NaN Values to 0\n",
    "    df['dead_back_log']=df['dead_back_log'].fillna(value=0) #replacing NaN Values to 0\n",
    "    #df['year_down']=df['year_down'].fillna(value=0) #replacing NaN Values to 0\n",
    "   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRANCH                0\n",
       "Campus                0\n",
       "Gender                0\n",
       "BE_Aggregate_Marks    0\n",
       "Semester1_Marks       0\n",
       "BackPapers1           0\n",
       "P_BackPapers1         0\n",
       "Semester2_Marks       0\n",
       "BackPapers2           0\n",
       "P_BackPapers2         0\n",
       "Semester3_Marks       0\n",
       "BackPapers3           0\n",
       "P_BackPapers3         0\n",
       "Semester4_Marks       0\n",
       "BackPapers4           0\n",
       "P_BackPapers4         0\n",
       "Semester5_Marks       0\n",
       "BackPapers5           0\n",
       "P_BackPapers5         0\n",
       "Semester6_Marks       0\n",
       "BackPapers6           0\n",
       "P_BackPapers6         0\n",
       "Semester7_Marks       0\n",
       "BackPapers7           0\n",
       "P_BackPapers7         0\n",
       "HSC_Marks             0\n",
       "SSC_Marks             0\n",
       "Diploma_Marks         0\n",
       "dead_back_log         0\n",
       "live_atkt             0\n",
       "Job Offer Count       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRANCH                 object\n",
       "Campus                 object\n",
       "Gender                 object\n",
       "BE_Aggregate_Marks    float64\n",
       "Semester1_Marks       float64\n",
       "BackPapers1           float64\n",
       "P_BackPapers1         float64\n",
       "Semester2_Marks       float64\n",
       "BackPapers2           float64\n",
       "P_BackPapers2         float64\n",
       "Semester3_Marks       float64\n",
       "BackPapers3           float64\n",
       "P_BackPapers3         float64\n",
       "Semester4_Marks       float64\n",
       "BackPapers4           float64\n",
       "P_BackPapers4         float64\n",
       "Semester5_Marks       float64\n",
       "BackPapers5           float64\n",
       "P_BackPapers5         float64\n",
       "Semester6_Marks       float64\n",
       "BackPapers6           float64\n",
       "P_BackPapers6         float64\n",
       "Semester7_Marks       float64\n",
       "BackPapers7           float64\n",
       "P_BackPapers7         float64\n",
       "HSC_Marks             float64\n",
       "SSC_Marks             float64\n",
       "Diploma_Marks         float64\n",
       "dead_back_log         float64\n",
       "live_atkt             float64\n",
       "Job Offer Count         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df['Diploma_Marks'].notnull() #findind all the values in diploma which are not null\n",
    "df.loc[m,'HSC_Marks']=df.loc[m,'HSC_Marks'].fillna(df['HSC_Marks'])  #replacing all diploma marks with 12th \n",
    "#df.drop(['Diploma_Marks']\n",
    "df['temp_y'] =df['Job Offer Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = LabelEncoder() \n",
    "# Encode labels in column 'in all'. \n",
    "label_encoder = LabelEncoder() \n",
    "# Encode labels in column 'in all'. \n",
    "#Degree_label_encoder= LabelEncoder()\n",
    "Campus_label_encoder= LabelEncoder()\n",
    "BRANCH_label_encoder= LabelEncoder()\n",
    "Gender_label_encoder= LabelEncoder()\n",
    "#df['Degree']= Degree_label_encoder.fit_transform(df['Degree'])\n",
    "df['Campus']= Campus_label_encoder.fit_transform(df['Campus'])\n",
    "df['BRANCH']= BRANCH_label_encoder.fit_transform(df['BRANCH'])\n",
    "df['Gender']= Gender_label_encoder.fit_transform(df['Gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>Campus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BE_Aggregate_Marks</th>\n",
       "      <th>Semester1_Marks</th>\n",
       "      <th>BackPapers1</th>\n",
       "      <th>P_BackPapers1</th>\n",
       "      <th>Semester2_Marks</th>\n",
       "      <th>BackPapers2</th>\n",
       "      <th>P_BackPapers2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_BackPapers6</th>\n",
       "      <th>Semester7_Marks</th>\n",
       "      <th>BackPapers7</th>\n",
       "      <th>P_BackPapers7</th>\n",
       "      <th>HSC_Marks</th>\n",
       "      <th>SSC_Marks</th>\n",
       "      <th>Diploma_Marks</th>\n",
       "      <th>dead_back_log</th>\n",
       "      <th>live_atkt</th>\n",
       "      <th>temp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.940000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.850000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.230000</td>\n",
       "      <td>90.360000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.674359</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.831629</td>\n",
       "      <td>85.521949</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.440000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.760000</td>\n",
       "      <td>92.200000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.674359</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.700000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRANCH  Campus  Gender  BE_Aggregate_Marks  Semester1_Marks  BackPapers1  \\\n",
       "0      12       0       1            6.750000         7.000000          1.0   \n",
       "1       0       2       1            6.660000         8.760000          0.0   \n",
       "2       9       2       1            7.674359         8.124134          0.0   \n",
       "3       2       1       1            8.440000         9.000000          0.0   \n",
       "4       9       1       1            7.674359         8.124134          0.0   \n",
       "\n",
       "   P_BackPapers1  Semester2_Marks  BackPapers2  P_BackPapers2  ...  \\\n",
       "0            0.0         6.940000          1.0            0.0  ...   \n",
       "1            0.0         7.640000          0.0            0.0  ...   \n",
       "2            0.0         7.869851          0.0            0.0  ...   \n",
       "3            0.0         8.620000          0.0            0.0  ...   \n",
       "4            0.0         7.869851          0.0            0.0  ...   \n",
       "\n",
       "   P_BackPapers6  Semester7_Marks  BackPapers7  P_BackPapers7  HSC_Marks  \\\n",
       "0            0.0         7.924697          0.0            0.0  73.850000   \n",
       "1            0.0         7.924697          0.0            0.0  79.230000   \n",
       "2            0.0         7.924697          0.0            0.0  77.831629   \n",
       "3            0.0         7.924697          0.0            0.0  76.760000   \n",
       "4            0.0         7.924697          0.0            0.0  86.700000   \n",
       "\n",
       "   SSC_Marks  Diploma_Marks  dead_back_log  live_atkt  temp_y  \n",
       "0  82.000000      82.196817            0.0        0.0       0  \n",
       "1  90.360000      82.196817            0.0        0.0       0  \n",
       "2  85.521949      82.196817            0.0        0.0       0  \n",
       "3  92.200000      82.196817            0.0        0.0       0  \n",
       "4  84.000000      82.196817            0.0        0.0       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Job Offer Count'], axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRANCH', 'Campus', 'Gender', 'BE_Aggregate_Marks', 'Semester1_Marks', 'BackPapers1', 'P_BackPapers1', 'Semester2_Marks', 'BackPapers2', 'P_BackPapers2', 'Semester3_Marks', 'BackPapers3', 'P_BackPapers3', 'Semester4_Marks', 'BackPapers4', 'P_BackPapers4', 'Semester5_Marks', 'BackPapers5', 'P_BackPapers5', 'Semester6_Marks', 'BackPapers6', 'P_BackPapers6', 'Semester7_Marks', 'BackPapers7', 'P_BackPapers7', 'HSC_Marks', 'SSC_Marks', 'Diploma_Marks', 'dead_back_log', 'live_atkt', 'temp_y']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "df_col_idx = [df.columns.get_loc(c) for c in df.columns.values if c in df]\n",
    "df_col_name = list(df.columns.values)\n",
    "print (df_col_name)\n",
    "print (df_col_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2194, 30)\n",
      "y: (2194,)\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,:len(df_col_idx)-1]    # predictors\n",
    "y = df['temp_y']     # target variable\n",
    "print(\"X:\",X.shape)\n",
    "print(\"y:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>Campus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BE_Aggregate_Marks</th>\n",
       "      <th>Semester1_Marks</th>\n",
       "      <th>BackPapers1</th>\n",
       "      <th>P_BackPapers1</th>\n",
       "      <th>Semester2_Marks</th>\n",
       "      <th>BackPapers2</th>\n",
       "      <th>P_BackPapers2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_BackPapers6</th>\n",
       "      <th>Semester7_Marks</th>\n",
       "      <th>BackPapers7</th>\n",
       "      <th>P_BackPapers7</th>\n",
       "      <th>HSC_Marks</th>\n",
       "      <th>SSC_Marks</th>\n",
       "      <th>Diploma_Marks</th>\n",
       "      <th>dead_back_log</th>\n",
       "      <th>live_atkt</th>\n",
       "      <th>temp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.940000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.850000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.230000</td>\n",
       "      <td>90.360000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.674359</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.831629</td>\n",
       "      <td>85.521949</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.440000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.760000</td>\n",
       "      <td>92.200000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.674359</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.700000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.290000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.690000</td>\n",
       "      <td>86.360000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.120000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.150000</td>\n",
       "      <td>77.820000</td>\n",
       "      <td>82.196817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.580000</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.831629</td>\n",
       "      <td>89.640000</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>8.124134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.869851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.924697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.831629</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>90.710000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRANCH  Campus  Gender  BE_Aggregate_Marks  Semester1_Marks  BackPapers1  \\\n",
       "0      12       0       1            6.750000         7.000000          1.0   \n",
       "1       0       2       1            6.660000         8.760000          0.0   \n",
       "2       9       2       1            7.674359         8.124134          0.0   \n",
       "3       2       1       1            8.440000         9.000000          0.0   \n",
       "4       9       1       1            7.674359         8.124134          0.0   \n",
       "5      12       0       1            8.290000         8.120000          0.0   \n",
       "6       7       2       1            7.170000         7.160000          1.0   \n",
       "7       5       2       1            8.140000         7.480000          2.0   \n",
       "8       7       1       1            7.580000         8.124134          0.0   \n",
       "9       9       2       1            9.240000         8.124134          0.0   \n",
       "\n",
       "   P_BackPapers1  Semester2_Marks  BackPapers2  P_BackPapers2  ...  \\\n",
       "0            0.0         6.940000          1.0            0.0  ...   \n",
       "1            0.0         7.640000          0.0            0.0  ...   \n",
       "2            0.0         7.869851          0.0            0.0  ...   \n",
       "3            0.0         8.620000          0.0            0.0  ...   \n",
       "4            0.0         7.869851          0.0            0.0  ...   \n",
       "5            0.0         8.260000          0.0            0.0  ...   \n",
       "6            0.0         7.120000          2.0            0.0  ...   \n",
       "7            0.0         7.920000          3.0            0.0  ...   \n",
       "8            0.0         7.869851          0.0            0.0  ...   \n",
       "9            0.0         7.869851          0.0            0.0  ...   \n",
       "\n",
       "   P_BackPapers6  Semester7_Marks  BackPapers7  P_BackPapers7  HSC_Marks  \\\n",
       "0            0.0         7.924697          0.0            0.0  73.850000   \n",
       "1            0.0         7.924697          0.0            0.0  79.230000   \n",
       "2            0.0         7.924697          0.0            0.0  77.831629   \n",
       "3            0.0         7.924697          0.0            0.0  76.760000   \n",
       "4            0.0         7.924697          0.0            0.0  86.700000   \n",
       "5            0.0         7.924697          0.0            0.0  85.690000   \n",
       "6            0.0         7.924697          0.0            0.0  80.000000   \n",
       "7            0.0         7.924697          0.0            0.0  66.150000   \n",
       "8            0.0         7.924697          0.0            0.0  77.831629   \n",
       "9            0.0         7.924697          0.0            0.0  77.831629   \n",
       "\n",
       "   SSC_Marks  Diploma_Marks  dead_back_log  live_atkt  temp_y  \n",
       "0  82.000000      82.196817            0.0        0.0       0  \n",
       "1  90.360000      82.196817            0.0        0.0       0  \n",
       "2  85.521949      82.196817            0.0        0.0       0  \n",
       "3  92.200000      82.196817            0.0        0.0       0  \n",
       "4  84.000000      82.196817            0.0        0.0       0  \n",
       "5  86.360000      82.196817            0.0        0.0       1  \n",
       "6  91.500000      82.196817            0.0        0.0       1  \n",
       "7  77.820000      82.196817            0.0        0.0       2  \n",
       "8  89.640000      80.750000            0.0        0.0       1  \n",
       "9  92.000000      90.710000            0.0        0.0       1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=2019)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import StandardScale` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler=StandardScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "#X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)\n",
    "#X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.699754 (0.039619)\n",
      "SVM: 0.712779 (0.038632)\n",
      "DTreeC: 0.681483 (0.031936)\n",
      "RF: 0.756986 (0.035511)\n",
      "NB: 0.166781 (0.032236)\n",
      "KNN: 0.688571 (0.035277)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "models_list = []\n",
    "\n",
    "models_list.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models_list.append(('SVM', SVC()))\n",
    "models_list.append(('DTreeC', DecisionTreeClassifier()))\n",
    "models_list.append(('RF', RandomForestClassifier(n_estimators=300, max_features=3)))\n",
    "models_list.append(('NB', GaussianNB()))\n",
    "models_list.append(('KNN', KNeighborsClassifier()))\n",
    "\n",
    "results = []\n",
    "algo_names = []\n",
    "\n",
    "for name, model in models_list:\n",
    "    kfold = KFold(n_splits=10, random_state=2019)\n",
    "    cross_val_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring = 'accuracy')\n",
    "    results.append(cross_val_results)\n",
    "    algo_names.append(name)\n",
    "    info = \"%s: %f (%f)\" % (name, cross_val_results.mean(), cross_val_results.std())\n",
    "    print(info)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Machine Learning Algorithms performance comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(algo_names)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Results...     Accuracy :  0.716358839050132\n",
      "\n",
      "Test Results...      Accuracy :  0.68\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       413\n",
      "           1       0.57      0.43      0.49       225\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.68       650\n",
      "   macro avg       0.43      0.42      0.42       650\n",
      "weighted avg       0.65      0.68      0.66       650\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[346  67   0]\n",
      " [129  96   0]\n",
      " [  7   5   0]]\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "\n",
      "Confusion matrix using Crosstab :\n",
      "Prediction    0    1  All\n",
      "Actual                   \n",
      "0           346   67  413\n",
      "1           129   96  225\n",
      "2             7    5   12\n",
      "All         482  168  650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logmodel=LogisticRegression(max_iter=1000)\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions=logmodel.predict(X_test)\n",
    "\n",
    "y_train_pred=logmodel.predict(X_train)\n",
    "print('\\n\\nTrain Results...     Accuracy : ',accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "y_test_pred=logmodel.predict(X_test)\n",
    "print('\\nTest Results...      Accuracy : ',accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(y_test,predictions)\n",
    "print(\"\\n\\nClassification Report:\\n\",report)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,predictions)\n",
    "print(\"\\nConfusion Matrix:\\n\",cm)\n",
    "\n",
    "accuracy=accuracy_score(y_test,predictions)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "print('\\n\\nConfusion matrix using Crosstab :')\n",
    "print(pd.crosstab(y_test,predictions,margins=True,rownames=['Actual'],colnames=['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Results...     Accuracy :  0.7137203166226913\n",
      "\n",
      "Test Results...      Accuracy :  0.6738461538461539\n",
      "\n",
      "\n",
      "confusion marix :\n",
      "[[347  66   0]\n",
      " [134  91   0]\n",
      " [  8   4   0]]\n",
      "\n",
      "\n",
      "Classification Reports :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77       413\n",
      "           1       0.57      0.40      0.47       225\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.67       650\n",
      "   macro avg       0.42      0.41      0.41       650\n",
      "weighted avg       0.65      0.67      0.65       650\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix using Crosstab :\n",
      "Prediction    0    1  All\n",
      "Actual                   \n",
      "0           347   66  413\n",
      "1           134   91  225\n",
      "2             8    4   12\n",
      "All         489  161  650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# linear SVM classifier\n",
    "\n",
    "#It uses a technique called the kernel trick to transform your data and then based on these transformations it finds an optimal boundary \n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "svm_model_linear.fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "\n",
    "y_train_pred=svm_model_linear.predict(X_train)\n",
    "print('\\n\\nTrain Results...     Accuracy : ',accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "y_test_pred=svm_model_linear.predict(X_test)\n",
    "print('\\nTest Results...      Accuracy : ',accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "print('\\n\\nconfusion marix :')\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print('\\n\\nClassification Reports :')\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "\n",
    "print('\\n\\nConfusion matrix using Crosstab :')\n",
    "print(pd.crosstab(y_test,y_test_pred,margins=True,rownames=['Actual'],colnames=['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Feature Importances : [0.         0.18445581 0.01789128 0.         0.12271713 0.\n",
      " 0.         0.         0.01054966 0.00849477 0.         0.\n",
      " 0.02150007 0.         0.29116701 0.         0.         0.10543634\n",
      " 0.         0.         0.04599777 0.         0.00550263 0.0388846\n",
      " 0.         0.         0.10182736 0.02450738 0.0210682  0.\n",
      " 0.        ]\n",
      "\n",
      "\n",
      "Train Results...     Accuracy :  0.8034300791556728\n",
      "\n",
      "Test Results...      Accuracy :  0.7246153846153847\n",
      "\n",
      "\n",
      "confusion marix :\n",
      "[[344  69   0]\n",
      " [ 97 127   1]\n",
      " [  5   7   0]]\n",
      "\n",
      "\n",
      "Classification Reports :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       413\n",
      "           1       0.63      0.56      0.59       225\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.72       650\n",
      "   macro avg       0.47      0.47      0.46       650\n",
      "weighted avg       0.71      0.72      0.71       650\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix using Crosstab :\n",
      "Prediction    0    1  2  All\n",
      "Actual                      \n",
      "0           344   69  0  413\n",
      "1            97  127  1  225\n",
      "2             5    7  0   12\n",
      "All         446  203  1  650\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "#The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features\n",
    "\n",
    "\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion='entropy',max_depth=6,random_state=2019)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('\\n\\nFeature Importances :', clf.feature_importances_)\n",
    "\n",
    "y_train_pred=clf.predict(X_train)\n",
    "print('\\n\\nTrain Results...     Accuracy : ',accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print('\\nTest Results...      Accuracy : ',accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "print('\\n\\nconfusion marix :')\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print('\\n\\nClassification Reports :')\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "\n",
    "\n",
    "print('\\n\\nConfusion matrix using Crosstab :')\n",
    "print(pd.crosstab(y_test,y_test_pred,margins=True,rownames=['Actual'],colnames=['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Feature Importances : [0.1378012  0.01857907 0.00751133 0.13131577 0.03938985 0.00505901\n",
      " 0.         0.05205398 0.00620191 0.         0.08103805 0.01544555\n",
      " 0.         0.13120316 0.00570451 0.00570871 0.03463365 0.00678501\n",
      " 0.00285717 0.08735955 0.00768735 0.0020267  0.02954076 0.0005469\n",
      " 0.00075672 0.0955834  0.04907459 0.02778727 0.01007221 0.00827661]\n",
      "\n",
      "\n",
      "Train Results...     Accuracy :  0.8625407166123779\n",
      "\n",
      "Test Results...      Accuracy :  0.7693474962063733\n",
      "\n",
      "\n",
      "confusion marix :\n",
      "[[389  48   0]\n",
      " [ 93 118   0]\n",
      " [  7   4   0]]\n",
      "\n",
      "\n",
      "Classification Reports :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       437\n",
      "           1       0.69      0.56      0.62       211\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.77       659\n",
      "   macro avg       0.50      0.48      0.49       659\n",
      "weighted avg       0.75      0.77      0.76       659\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix using Crosstab :\n",
      "Prediction    0    1  All\n",
      "Actual                   \n",
      "0           389   48  437\n",
      "1            93  118  211\n",
      "2             7    4   11\n",
      "All         489  170  659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "#Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting.\n",
    "# Random Forest\n",
    "\n",
    "#Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_trees = 10\n",
    "n_jobs = -1 \n",
    "\n",
    "rd = RandomForestClassifier(n_estimators=num_trees,max_leaf_nodes=65,n_jobs=n_jobs,random_state=2019)\n",
    "rd.fit(X_train, y_train)\n",
    "y_pred=rd.predict(X_test)\n",
    "print('\\n\\nFeature Importances :', rd.feature_importances_)\n",
    "\n",
    "y_train_pred=rd.predict(X_train)\n",
    "print('\\n\\nTrain Results...     Accuracy : ',accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "y_test_pred=rd.predict(X_test)\n",
    "print('\\nTest Results...      Accuracy : ',accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "print('\\n\\nconfusion marix :')\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print('\\n\\nClassification Reports :')\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "\n",
    "print('\\n\\nConfusion matrix using Crosstab :')\n",
    "print(pd.crosstab(y_test,y_test_pred,margins=True,rownames=['Actual'],colnames=['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-Accuracy: 0.16939139292080468\n",
      "Train------ Accuracy: 0.1719869706840391\n",
      "Test------ Accuracy: 0.16995447647951442\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "#It predicts membership probabilities for each class such as the probability that given record or data point belongs to a particular class. \n",
    "#It's also assumed that all the features are following a gaussian distribution i.e, normal distribution.\n",
    "\n",
    "\n",
    "num_folds=10\n",
    "\n",
    "kfold=StratifiedKFold(n_splits=num_folds,random_state=2019)\n",
    "\n",
    "\n",
    "gnb_clf=GaussianNB()\n",
    "gnb_clf.fit(X_train,y_train)\n",
    "results=cross_val_score(gnb_clf,X_train,y_train,cv=kfold)\n",
    "print(\"CV-Accuracy:\" ,results.mean())\n",
    "\n",
    "\n",
    "y_train_pred=gnb_clf.predict(X_train)\n",
    "print(\"Train------ Accuracy:\",accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "\n",
    "y_test_pred=gnb_clf.predict(X_test)\n",
    "print(\"Test------ Accuracy:\",accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-Accuracy: 0.7018342628093412\n",
      "Train------ Accuracy: 0.7704485488126649\n",
      "Test------ Accuracy: 0.6892307692307692\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "#Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "k=7\n",
    "\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=k)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "results=cross_val_score(knn_clf,X_train,y_train,cv=kfold)\n",
    "print(\"CV-Accuracy:\" ,results.mean())\n",
    "\n",
    "\n",
    "y_train_pred=knn_clf.predict(X_train)\n",
    "print(\"Train------ Accuracy:\",accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "\n",
    "y_test_pred=knn_clf.predict(X_test)\n",
    "print(\"Test------ Accuracy:\",accuracy_score(y_test,y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing single record for prediction of placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Degree', 'BRANCH', 'Campus', 'Gender', 'BE_Aggregate_Marks', 'Semester1_Marks', 'BackPapers1', 'P_BackPapers1', 'Semester2_Marks', 'BackPapers2', 'P_BackPapers2', 'Semester3_Marks', 'BackPapers3', 'P_BackPapers3', 'Semester4_Marks', 'BackPapers4', 'P_BackPapers4', 'Semester5_Marks', 'BackPapers5', 'P_BackPapers5', 'Semester6_Marks', 'BackPapers6', 'P_BackPapers6', 'Semester7_Marks', 'BackPapers7', 'P_BackPapers7', 'HSC_Marks', 'SSC_Marks', 'Diploma_Marks', 'dead_back_log', 'live_atkt','temp_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 2,\n",
       " 0,\n",
       " 9.14,\n",
       " 9.48,\n",
       " 0,\n",
       " 0,\n",
       " 9.92,\n",
       " 0,\n",
       " 0,\n",
       " 6.0,\n",
       " 0,\n",
       " 0,\n",
       " 9.0,\n",
       " 0,\n",
       " 0,\n",
       " 9.39,\n",
       " 0,\n",
       " 0,\n",
       " 9.05,\n",
       " 0,\n",
       " 0,\n",
       " 9.5,\n",
       " 0,\n",
       " 0,\n",
       " 86.15,\n",
       " 98,\n",
       " 88,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_record=['Electronics & Telecommunication Engineering (E&TC)','MITCOE','Female',9.14,9.48,0,0,9.92,0,0,6.0,0,0,9.0,0,0,9.39,0,0,9.05,0,0,9.5,0,0,86.15,98,88,0,0]\n",
    "#test_record[0]=Degree_label_encoder.fit_transform([test_record[0]])[0]             \n",
    "test_record[0]=BRANCH_label_encoder.transform([test_record[0]])[0]\n",
    "test_record[1]=Campus_label_encoder.transform([test_record[1]])[0]\n",
    "test_record[2]=Gender_label_encoder.transform([test_record[2]])[0]\n",
    "test_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22180477,  1.20930487, -1.55521968,  1.70938489,  1.55798345,\n",
       "        -0.28569561, -0.02553215,  2.32340867, -0.37220471, -0.03096703,\n",
       "        -2.11795161, -0.4271708 , -0.08715302,  1.53814368, -0.33364691,\n",
       "        -0.08788344,  1.94736735, -0.38055018, -0.16681516,  1.58779061,\n",
       "        -0.24565567, -0.17983383,  3.00895531, -0.08472187, -0.10018574,\n",
       "         0.97431857,  1.10115946,  1.26023712, -0.3510486 , -0.26224888]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standarize_new_record=standard_scaler.transform([test_record])\n",
    "standarize_new_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newrecord_pred = rd.predict(standarize_new_record)\n",
    "newrecord_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
